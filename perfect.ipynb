{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of folders = shpae, x \n",
    "# folders should not be empty\n",
    "# fix shape 22500 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-19T18:51:41.274490Z",
     "iopub.status.busy": "2022-11-19T18:51:41.274118Z",
     "iopub.status.idle": "2022-11-19T18:51:47.396242Z",
     "shell.execute_reply": "2022-11-19T18:51:47.395363Z",
     "shell.execute_reply.started": "2022-11-19T18:51:41.274389Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import expand_dims\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Input, Lambda\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-19T18:51:47.398548Z",
     "iopub.status.busy": "2022-11-19T18:51:47.397915Z",
     "iopub.status.idle": "2022-11-19T18:51:56.371281Z",
     "shell.execute_reply": "2022-11-19T18:51:56.370189Z",
     "shell.execute_reply.started": "2022-11-19T18:51:47.398509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\user\\anaconda3\\lib\\site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo\n",
    "\n",
    "create subset of clients\n",
    "\n",
    "- increase comm rounds 300\n",
    "- increase hidden units 400\n",
    "- increase no of layers\n",
    "- no of clients 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-19T18:51:56.375437Z",
     "iopub.status.busy": "2022-11-19T18:51:56.374830Z",
     "iopub.status.idle": "2022-11-19T18:51:56.381254Z",
     "shell.execute_reply": "2022-11-19T18:51:56.380318Z",
     "shell.execute_reply.started": "2022-11-19T18:51:56.375365Z"
    }
   },
   "outputs": [],
   "source": [
    "debug = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-19T18:51:56.383718Z",
     "iopub.status.busy": "2022-11-19T18:51:56.383209Z",
     "iopub.status.idle": "2022-11-19T18:51:56.403838Z",
     "shell.execute_reply": "2022-11-19T18:51:56.402761Z",
     "shell.execute_reply.started": "2022-11-19T18:51:56.383679Z"
    }
   },
   "outputs": [],
   "source": [
    "def load(paths, verbose=-1):\n",
    "    '''expects images for each class in seperate dir, \n",
    "    e.g all digits in 0 class in the directory named 0 '''\n",
    "    data = list()\n",
    "    labels = list()\n",
    "    # loop over the input images\n",
    "    for (i, imgpath) in enumerate(paths):\n",
    "        # load the image and extract the class labels        \n",
    "        im_gray = cv2.imread(imgpath , cv2.IMREAD_GRAYSCALE)\n",
    "        image = np.array(im_gray).flatten() # cv2.imread(imgpath) \n",
    "        # print(image.shape)\n",
    "        label = imgpath.split(os.path.sep)[-2]\n",
    "        # scale the image to [0, 1] and add to list\n",
    "        data.append(image/255)\n",
    "        labels.append(label)\n",
    "        # show an update every `verbose` images\n",
    "        if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i + 1, len(paths)))\n",
    "    # return a tuple of the data and labels\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "def create_clients(image_list, label_list, num_clients=100, initial='clients'):\n",
    "    ''' return: a dictionary with keys clients' names and value as \n",
    "                data shards - tuple of images and label lists.\n",
    "        args: \n",
    "            image_list: a list of numpy arrays of training images\n",
    "            label_list:a list of binarized labels for each image\n",
    "            num_client: number of fedrated members (clients)\n",
    "            initials: the clients'name prefix, e.g, clients_1 \n",
    "            \n",
    "    '''\n",
    "\n",
    "    #create a list of client names\n",
    "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
    "\n",
    "    #randomize the data\n",
    "    data = list(zip(image_list, label_list))\n",
    "    random.shuffle(data)  # <- IID\n",
    "    \n",
    "    # sort data for non-iid\n",
    "#     max_y = np.argmax(label_list, axis=-1)\n",
    "#     sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
    "#     data = [(x,y) for _,y,x in sorted_zip]\n",
    "\n",
    "    #shard data and place at each client\n",
    "    size = len(data)//num_clients\n",
    "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "\n",
    "    #number of clients must equal number of shards\n",
    "    assert(len(shards) == len(client_names))\n",
    "\n",
    "    return {client_names[i] : shards[i] for i in range(len(client_names))} \n",
    "\n",
    "\n",
    "def batch_data(data_shard, bs=32):\n",
    "    '''Takes in a clients data shard and create a tfds object off it\n",
    "    args:\n",
    "        shard: a data, label constituting a client's data shard\n",
    "        bs:batch size\n",
    "    return:\n",
    "        tfds object'''\n",
    "    #seperate shard into data and labels lists\n",
    "    data, label = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "    return dataset.shuffle(len(label)).batch(bs)\n",
    "\n",
    "\n",
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    # get the total number of data points held by a client\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    \n",
    "    \n",
    "    if debug:\n",
    "        print('global_count', global_count, 'local_count', local_count, 'bs', bs)\n",
    "    \n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    #logits = model.predict(X_test, batch_size=100)\n",
    "    logits = model.predict(X_test)\n",
    "    loss = cce(Y_test, logits)\n",
    "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "    return acc, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-19T18:51:56.405917Z",
     "iopub.status.busy": "2022-11-19T18:51:56.405476Z",
     "iopub.status.idle": "2022-11-19T18:51:56.417235Z",
     "shell.execute_reply": "2022-11-19T18:51:56.416403Z",
     "shell.execute_reply.started": "2022-11-19T18:51:56.405877Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(shape, classes):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(200, input_shape=(shape,)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-11-19T18:51:56.419060Z",
     "iopub.status.busy": "2022-11-19T18:51:56.418610Z",
     "iopub.status.idle": "2022-11-19T18:57:39.942507Z",
     "shell.execute_reply": "2022-11-19T18:57:39.941518Z",
     "shell.execute_reply.started": "2022-11-19T18:51:56.419021Z"
    }
   },
   "outputs": [],
   "source": [
    "#declear path to your mnist data folder\n",
    "img_path = 'low sized/sadidata' #'../input/cifar10-pngs-in-folders/cifar10/test'  # <-- test dataset #'../input/mnistasjpg/trainingSample/trainingSample' # <-- smaller dataset\n",
    "\n",
    "#get the path list using the path object\n",
    "image_paths = list(paths.list_images(img_path))\n",
    "\n",
    "#apply our function\n",
    "image_list, label_list = load(image_paths, verbose=10000)\n",
    "\n",
    "#binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "label_list = lb.fit_transform(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-19T18:57:39.944266Z",
     "iopub.status.busy": "2022-11-19T18:57:39.943904Z",
     "iopub.status.idle": "2022-11-19T18:57:39.970267Z",
     "shell.execute_reply": "2022-11-19T18:57:39.969296Z",
     "shell.execute_reply.started": "2022-11-19T18:57:39.944223Z"
    }
   },
   "outputs": [],
   "source": [
    "#split data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_list, \n",
    "                                                    label_list, \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-19T18:57:39.973519Z",
     "iopub.status.busy": "2022-11-19T18:57:39.973115Z",
     "iopub.status.idle": "2022-11-19T18:57:39.984407Z",
     "shell.execute_reply": "2022-11-19T18:57:39.983207Z",
     "shell.execute_reply.started": "2022-11-19T18:57:39.973461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2879, 320, 2879, 320)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-19T18:57:39.987846Z",
     "iopub.status.busy": "2022-11-19T18:57:39.987400Z",
     "iopub.status.idle": "2022-11-19T18:57:40.050835Z",
     "shell.execute_reply": "2022-11-19T18:57:40.049934Z",
     "shell.execute_reply.started": "2022-11-19T18:57:39.987807Z"
    }
   },
   "outputs": [],
   "source": [
    "#create clients\n",
    "clients = create_clients(X_train, y_train, num_clients=100, initial='client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-19T18:57:40.052799Z",
     "iopub.status.busy": "2022-11-19T18:57:40.052336Z",
     "iopub.status.idle": "2022-11-19T18:57:40.057078Z",
     "shell.execute_reply": "2022-11-19T18:57:40.055868Z",
     "shell.execute_reply.started": "2022-11-19T18:57:40.052756Z"
    }
   },
   "outputs": [],
   "source": [
    "# client_names = ['{}_{}'.format('client', i+1) for i in range(100)]\n",
    "# s = clients['client_1'][0][1]*0\n",
    "# for c in client_names:\n",
    "#     sum = clients[c][0][1]\n",
    "#     for i in range(1,378):\n",
    "#         sum = sum + clients[c][i][1]\n",
    "        \n",
    "#     s = s + sum/378\n",
    "# s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-19T18:57:40.059150Z",
     "iopub.status.busy": "2022-11-19T18:57:40.058684Z",
     "iopub.status.idle": "2022-11-19T18:57:47.618948Z",
     "shell.execute_reply": "2022-11-19T18:57:47.617902Z",
     "shell.execute_reply.started": "2022-11-19T18:57:40.059110Z"
    }
   },
   "outputs": [],
   "source": [
    "#process and batch the training data for each client\n",
    "clients_batched = dict()\n",
    "for (client_name, data) in clients.items():\n",
    "    clients_batched[client_name] = batch_data(data)\n",
    "    \n",
    "#process and batch the test set  \n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-19T18:57:47.620936Z",
     "iopub.status.busy": "2022-11-19T18:57:47.620548Z",
     "iopub.status.idle": "2022-11-19T18:57:47.627876Z",
     "shell.execute_reply": "2022-11-19T18:57:47.626622Z",
     "shell.execute_reply.started": "2022-11-19T18:57:47.620895Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "comms_round = 300\n",
    "loss='categorical_crossentropy'\n",
    "# loss = 'sparse_categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "optimizer = SGD(lr=lr, \n",
    "                decay=lr / comms_round, \n",
    "                momentum=0.9\n",
    "               )          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-19T18:57:47.630858Z",
     "iopub.status.busy": "2022-11-19T18:57:47.629917Z",
     "iopub.status.idle": "2022-11-19T18:57:48.064256Z",
     "shell.execute_reply": "2022-11-19T18:57:48.063260Z",
     "shell.execute_reply.started": "2022-11-19T18:57:47.630813Z"
    }
   },
   "outputs": [],
   "source": [
    "#initialize global model\n",
    "\n",
    "build_shape = 22500 #(28, 28, 3)  # 1024 <- CIFAR-10    # 784 # for MNIST\n",
    "\n",
    "smlp_global = SimpleMLP()\n",
    "#dee: number of folders\n",
    "global_model = smlp_global.build(build_shape, 4) \n",
    "global_acc_list = []\n",
    "global_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-19T18:57:48.066003Z",
     "iopub.status.busy": "2022-11-19T18:57:48.065668Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 0 | global_acc: 26.250% | global_loss: 1.464123249053955\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 1 | global_acc: 29.063% | global_loss: 1.4106796979904175\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 2 | global_acc: 22.188% | global_loss: 1.4811794757843018\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 3 | global_acc: 22.500% | global_loss: 1.5333389043807983\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 4 | global_acc: 26.250% | global_loss: 1.4012231826782227\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "comm_round: 5 | global_acc: 29.375% | global_loss: 1.3852001428604126\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 6 | global_acc: 22.500% | global_loss: 1.41471266746521\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 7 | global_acc: 27.500% | global_loss: 1.3649604320526123\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 8 | global_acc: 36.250% | global_loss: 1.3669259548187256\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "comm_round: 9 | global_acc: 38.125% | global_loss: 1.3627746105194092\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 10 | global_acc: 22.500% | global_loss: 1.3609559535980225\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "comm_round: 11 | global_acc: 44.062% | global_loss: 1.3599079847335815\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 12 | global_acc: 47.500% | global_loss: 1.3524595499038696\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 13 | global_acc: 50.625% | global_loss: 1.3496854305267334\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 14 | global_acc: 41.250% | global_loss: 1.336958885192871\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 15 | global_acc: 50.313% | global_loss: 1.3352854251861572\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 16 | global_acc: 65.625% | global_loss: 1.3277086019515991\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 17 | global_acc: 21.562% | global_loss: 1.3766109943389893\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "comm_round: 18 | global_acc: 42.500% | global_loss: 1.369824767112732\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 19 | global_acc: 37.812% | global_loss: 1.360485315322876\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 20 | global_acc: 45.625% | global_loss: 1.3559058904647827\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 21 | global_acc: 44.062% | global_loss: 1.340458869934082\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 22 | global_acc: 47.812% | global_loss: 1.3333051204681396\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 23 | global_acc: 47.812% | global_loss: 1.324339509010315\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "comm_round: 24 | global_acc: 43.750% | global_loss: 1.3377166986465454\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 25 | global_acc: 41.562% | global_loss: 1.308280348777771\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 26 | global_acc: 48.438% | global_loss: 1.323068618774414\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 27 | global_acc: 37.500% | global_loss: 1.3090999126434326\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "comm_round: 28 | global_acc: 41.875% | global_loss: 1.3119256496429443\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "comm_round: 29 | global_acc: 57.500% | global_loss: 1.3012853860855103\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 30 | global_acc: 22.812% | global_loss: 1.3331148624420166\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 31 | global_acc: 47.188% | global_loss: 1.3245677947998047\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 32 | global_acc: 68.125% | global_loss: 1.306759238243103\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "comm_round: 33 | global_acc: 64.375% | global_loss: 1.2922149896621704\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 34 | global_acc: 50.000% | global_loss: 1.2954968214035034\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "comm_round: 35 | global_acc: 41.250% | global_loss: 1.2944731712341309\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 36 | global_acc: 32.188% | global_loss: 1.2967780828475952\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 37 | global_acc: 61.562% | global_loss: 1.295331597328186\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 38 | global_acc: 55.000% | global_loss: 1.2902586460113525\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "comm_round: 39 | global_acc: 58.125% | global_loss: 1.2827556133270264\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 40 | global_acc: 43.438% | global_loss: 1.2954542636871338\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 41 | global_acc: 53.750% | global_loss: 1.2872819900512695\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 42 | global_acc: 45.000% | global_loss: 1.27431321144104\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 43 | global_acc: 47.188% | global_loss: 1.2864296436309814\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 44 | global_acc: 56.563% | global_loss: 1.2734321355819702\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 45 | global_acc: 55.312% | global_loss: 1.2587817907333374\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 46 | global_acc: 66.250% | global_loss: 1.2338857650756836\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 47 | global_acc: 79.688% | global_loss: 1.2202688455581665\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 48 | global_acc: 65.625% | global_loss: 1.2336453199386597\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 49 | global_acc: 57.812% | global_loss: 1.2357499599456787\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 50 | global_acc: 25.625% | global_loss: 1.3139222860336304\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 51 | global_acc: 51.562% | global_loss: 1.2927329540252686\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 52 | global_acc: 60.625% | global_loss: 1.2554070949554443\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 53 | global_acc: 68.125% | global_loss: 1.2401933670043945\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 54 | global_acc: 51.562% | global_loss: 1.249584436416626\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 55 | global_acc: 44.375% | global_loss: 1.2573734521865845\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 56 | global_acc: 59.062% | global_loss: 1.218722939491272\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 57 | global_acc: 68.125% | global_loss: 1.2001311779022217\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 58 | global_acc: 71.250% | global_loss: 1.1977481842041016\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 59 | global_acc: 70.312% | global_loss: 1.1878275871276855\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 60 | global_acc: 58.438% | global_loss: 1.20375657081604\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 61 | global_acc: 44.688% | global_loss: 1.2548795938491821\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 62 | global_acc: 57.188% | global_loss: 1.2617502212524414\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 63 | global_acc: 54.688% | global_loss: 1.2398109436035156\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 64 | global_acc: 73.438% | global_loss: 1.2216860055923462\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 65 | global_acc: 78.438% | global_loss: 1.1836313009262085\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 66 | global_acc: 62.813% | global_loss: 1.1946443319320679\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 67 | global_acc: 80.625% | global_loss: 1.165247917175293\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 68 | global_acc: 76.562% | global_loss: 1.172052025794983\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 69 | global_acc: 63.125% | global_loss: 1.1608266830444336\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 70 | global_acc: 69.062% | global_loss: 1.1842142343521118\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 71 | global_acc: 59.375% | global_loss: 1.1886012554168701\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 72 | global_acc: 41.875% | global_loss: 1.2429192066192627\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 73 | global_acc: 37.500% | global_loss: 1.2883013486862183\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 74 | global_acc: 44.375% | global_loss: 1.2519772052764893\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 75 | global_acc: 31.250% | global_loss: 1.3056905269622803\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 76 | global_acc: 38.438% | global_loss: 1.2719262838363647\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 77 | global_acc: 55.937% | global_loss: 1.2579708099365234\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 78 | global_acc: 80.625% | global_loss: 1.2218431234359741\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 79 | global_acc: 71.250% | global_loss: 1.1658293008804321\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 80 | global_acc: 80.938% | global_loss: 1.1526321172714233\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "comm_round: 81 | global_acc: 70.312% | global_loss: 1.137780785560608\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 82 | global_acc: 77.188% | global_loss: 1.1357574462890625\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 83 | global_acc: 64.375% | global_loss: 1.1451739072799683\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 84 | global_acc: 66.875% | global_loss: 1.1384227275848389\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 85 | global_acc: 65.938% | global_loss: 1.1394414901733398\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 86 | global_acc: 55.312% | global_loss: 1.1648914813995361\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 87 | global_acc: 72.500% | global_loss: 1.1653082370758057\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 88 | global_acc: 69.375% | global_loss: 1.1363309621810913\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 89 | global_acc: 69.688% | global_loss: 1.1699206829071045\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 90 | global_acc: 44.375% | global_loss: 1.2386109828948975\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 91 | global_acc: 71.250% | global_loss: 1.1960430145263672\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 92 | global_acc: 74.688% | global_loss: 1.1547046899795532\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 93 | global_acc: 75.000% | global_loss: 1.1229195594787598\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 94 | global_acc: 78.125% | global_loss: 1.1315138339996338\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "comm_round: 95 | global_acc: 78.438% | global_loss: 1.1164183616638184\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 96 | global_acc: 74.062% | global_loss: 1.102362871170044\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 97 | global_acc: 65.312% | global_loss: 1.1118730306625366\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 98 | global_acc: 69.375% | global_loss: 1.1277776956558228\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 99 | global_acc: 71.562% | global_loss: 1.0954573154449463\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 100 | global_acc: 69.375% | global_loss: 1.1211988925933838\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 101 | global_acc: 68.750% | global_loss: 1.1072540283203125\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 102 | global_acc: 70.625% | global_loss: 1.1166255474090576\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 103 | global_acc: 60.312% | global_loss: 1.1473462581634521\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 104 | global_acc: 58.750% | global_loss: 1.1535604000091553\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 105 | global_acc: 73.438% | global_loss: 1.109534502029419\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 106 | global_acc: 87.188% | global_loss: 1.082301378250122\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 107 | global_acc: 79.688% | global_loss: 1.0773000717163086\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 108 | global_acc: 84.062% | global_loss: 1.075049638748169\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 109 | global_acc: 78.750% | global_loss: 1.0995914936065674\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 110 | global_acc: 61.250% | global_loss: 1.1163431406021118\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 111 | global_acc: 72.188% | global_loss: 1.1192495822906494\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 112 | global_acc: 74.062% | global_loss: 1.0896995067596436\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 113 | global_acc: 75.000% | global_loss: 1.1366221904754639\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 114 | global_acc: 63.750% | global_loss: 1.1804636716842651\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 115 | global_acc: 64.062% | global_loss: 1.1525294780731201\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "comm_round: 116 | global_acc: 81.875% | global_loss: 1.1027482748031616\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 117 | global_acc: 77.188% | global_loss: 1.0935369729995728\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 118 | global_acc: 74.688% | global_loss: 1.0991789102554321\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 119 | global_acc: 69.062% | global_loss: 1.1108226776123047\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 120 | global_acc: 75.938% | global_loss: 1.0809705257415771\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "comm_round: 121 | global_acc: 73.438% | global_loss: 1.1030807495117188\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 122 | global_acc: 77.812% | global_loss: 1.0836189985275269\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 123 | global_acc: 75.625% | global_loss: 1.0758557319641113\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 124 | global_acc: 55.000% | global_loss: 1.1934186220169067\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 125 | global_acc: 58.750% | global_loss: 1.1636948585510254\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 126 | global_acc: 45.312% | global_loss: 1.2189356088638306\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 127 | global_acc: 62.187% | global_loss: 1.1925361156463623\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 128 | global_acc: 71.875% | global_loss: 1.1476033926010132\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 129 | global_acc: 71.562% | global_loss: 1.0969743728637695\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 130 | global_acc: 76.250% | global_loss: 1.0654089450836182\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 131 | global_acc: 77.188% | global_loss: 1.0560325384140015\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 132 | global_acc: 84.688% | global_loss: 1.078565001487732\n",
      "10/10 [==============================] - 0s 13ms/step\n",
      "comm_round: 133 | global_acc: 69.062% | global_loss: 1.0902817249298096\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 134 | global_acc: 79.688% | global_loss: 1.054989218711853\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 135 | global_acc: 69.062% | global_loss: 1.058160424232483\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 136 | global_acc: 77.188% | global_loss: 1.0871931314468384\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 137 | global_acc: 73.438% | global_loss: 1.0865658521652222\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 138 | global_acc: 79.688% | global_loss: 1.0306575298309326\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 139 | global_acc: 71.250% | global_loss: 1.055768609046936\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 140 | global_acc: 70.938% | global_loss: 1.0779485702514648\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 141 | global_acc: 63.438% | global_loss: 1.1091396808624268\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 142 | global_acc: 60.312% | global_loss: 1.1432158946990967\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 143 | global_acc: 70.000% | global_loss: 1.0905795097351074\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 144 | global_acc: 58.438% | global_loss: 1.1418304443359375\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 145 | global_acc: 68.125% | global_loss: 1.0927493572235107\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 146 | global_acc: 73.750% | global_loss: 1.0670839548110962\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 147 | global_acc: 79.688% | global_loss: 1.0481822490692139\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 148 | global_acc: 74.062% | global_loss: 1.069277286529541\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 149 | global_acc: 81.250% | global_loss: 1.0628011226654053\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 150 | global_acc: 83.750% | global_loss: 1.0676788091659546\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 151 | global_acc: 75.000% | global_loss: 1.0360901355743408\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 152 | global_acc: 89.688% | global_loss: 1.0382232666015625\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 153 | global_acc: 73.438% | global_loss: 1.0287058353424072\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 154 | global_acc: 80.625% | global_loss: 1.077269196510315\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "comm_round: 155 | global_acc: 67.188% | global_loss: 1.098313570022583\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 156 | global_acc: 75.938% | global_loss: 1.0564167499542236\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 157 | global_acc: 86.562% | global_loss: 1.0302444696426392\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 158 | global_acc: 82.188% | global_loss: 1.0312708616256714\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 159 | global_acc: 87.188% | global_loss: 1.0146198272705078\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 160 | global_acc: 79.688% | global_loss: 1.0361146926879883\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 161 | global_acc: 66.562% | global_loss: 1.067413568496704\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 162 | global_acc: 77.188% | global_loss: 1.0717719793319702\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 163 | global_acc: 85.625% | global_loss: 1.0315231084823608\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 164 | global_acc: 88.750% | global_loss: 1.0289943218231201\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 165 | global_acc: 70.312% | global_loss: 1.037036657333374\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 166 | global_acc: 90.625% | global_loss: 1.0169330835342407\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 167 | global_acc: 70.938% | global_loss: 1.0336432456970215\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 168 | global_acc: 75.000% | global_loss: 1.1095889806747437\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 169 | global_acc: 72.188% | global_loss: 1.076642632484436\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 170 | global_acc: 78.438% | global_loss: 1.0484634637832642\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 171 | global_acc: 84.375% | global_loss: 1.0391496419906616\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 172 | global_acc: 80.000% | global_loss: 1.0286853313446045\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "comm_round: 173 | global_acc: 86.562% | global_loss: 1.0223748683929443\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 174 | global_acc: 75.625% | global_loss: 1.0791279077529907\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 175 | global_acc: 63.750% | global_loss: 1.0747041702270508\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 176 | global_acc: 57.812% | global_loss: 1.153518557548523\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 177 | global_acc: 58.125% | global_loss: 1.2033545970916748\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 178 | global_acc: 54.688% | global_loss: 1.192678451538086\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 179 | global_acc: 76.875% | global_loss: 1.1084709167480469\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 180 | global_acc: 76.250% | global_loss: 1.0545051097869873\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 181 | global_acc: 84.375% | global_loss: 1.0596317052841187\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 182 | global_acc: 81.562% | global_loss: 1.0224491357803345\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 183 | global_acc: 83.750% | global_loss: 1.0495030879974365\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "comm_round: 184 | global_acc: 73.125% | global_loss: 1.041976809501648\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 185 | global_acc: 80.938% | global_loss: 1.024079442024231\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 186 | global_acc: 75.938% | global_loss: 1.0030450820922852\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "comm_round: 187 | global_acc: 81.250% | global_loss: 1.0193442106246948\n"
     ]
    }
   ],
   "source": [
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "            \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    all_client_names = list(clients_batched.keys())\n",
    "           \n",
    "    client_names = random.sample(all_client_names, k=10)\n",
    "    # print(client_names, len(client_names))\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "#     if debug: \n",
    "#         # print('all_client_names', all_client_names)\n",
    "#         print('client_names', client_names, len(client_names))\n",
    "                \n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        smlp_local = SimpleMLP()\n",
    "        #dee: build shape, number of folders\n",
    "        local_model = smlp_local.build(build_shape, 4)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = 0.1 # weight_scalling_factor(clients_batched, client)\n",
    "        # print('scaling_factor', scaling_factor)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "\n",
    "    #test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n",
    "        global_acc_list.append(global_acc)\n",
    "        global_loss_list.append(global_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'global_loss_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7ea179522604>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_loss_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_loss_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m122\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_acc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_acc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'global_loss_list' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IID \n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(list(range(0,len(global_loss_list))), global_loss_list)\n",
    "plt.subplot(122)\n",
    "plt.plot(list(range(0,len(global_acc_list))), global_acc_list)\n",
    "print('IID | total comm rounds', len(global_acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid_df = pd.DataFrame(list(zip(global_acc_list, global_loss_list)), columns =['global_acc_list', 'global_loss_list'])\n",
    "iid_df.to_csv('MNIST_IID.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients(image_list, label_list, num_clients=100, initial='clients'):\n",
    "    ''' return: a dictionary with keys clients' names and value as \n",
    "                data shards - tuple of images and label lists.\n",
    "        args: \n",
    "            image_list: a list of numpy arrays of training images\n",
    "            label_list:a list of binarized labels for each image\n",
    "            num_client: number of fedrated members (clients)\n",
    "            initials: the clients'name prefix, e.g, clients_1 \n",
    "            \n",
    "    '''\n",
    "\n",
    "    #create a list of client names\n",
    "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
    "\n",
    "    #randomize the data\n",
    "    # data = list(zip(image_list, label_list))\n",
    "    # random.shuffle(data)  # <- IID\n",
    "    \n",
    "    # sort data for non-iid\n",
    "    max_y = np.argmax(label_list, axis=-1)\n",
    "    sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
    "    data = [(x,y) for _,y,x in sorted_zip]\n",
    "\n",
    "    #shard data and place at each client\n",
    "    size = len(data)//num_clients\n",
    "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "\n",
    "    #number of clients must equal number of shards\n",
    "    assert(len(shards) == len(client_names))\n",
    "\n",
    "    return {client_names[i] : shards[i] for i in range(len(client_names))} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15609, 1735, 15609, 1735)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clients\n",
    "clients = create_clients(X_train, y_train, num_clients=100, initial='client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process and batch the training data for each client\n",
    "clients_batched = dict()\n",
    "for (client_name, data) in clients.items():\n",
    "    clients_batched[client_name] = batch_data(data)\n",
    "    \n",
    "#process and batch the test set  \n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01 \n",
    "comms_round = 180\n",
    "loss='categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "optimizer = SGD(lr=lr, \n",
    "                decay=lr / comms_round, \n",
    "                momentum=0.9\n",
    "               )          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize global model\n",
    "\n",
    "build_shape = 784 #(32, 32, 3)  # 1024 <- CIFAR-10    # 784 # for MNIST\n",
    "\n",
    "smlp_global = SimpleMLP()\n",
    "global_model = smlp_global.build(build_shape, 10) \n",
    "global_acc_list = []\n",
    "global_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 4) and (None, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-141f5945eeba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#fit local model with client's data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mlocal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclients_batched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m#scale the model weights and add to list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 4) and (None, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "            \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    all_client_names = list(clients_batched.keys())\n",
    "           \n",
    "    client_names = random.sample(all_client_names, k=10)\n",
    "    random.shuffle(client_names)\n",
    "    if debug: \n",
    "        # print('all_client_names', all_client_names)\n",
    "        print('client_names', client_names)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        smlp_local = SimpleMLP()\n",
    "        local_model = smlp_local.build(build_shape, 10)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = 0.1 # weight_scalling_factor(clients_batched, client)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "\n",
    "    #test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n",
    "        global_acc_list.append(global_acc)\n",
    "        global_loss_list.append(global_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-IID \n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(list(range(0,len(global_loss_list))), global_loss_list)\n",
    "plt.subplot(122)\n",
    "plt.plot(list(range(0,len(global_acc_list))), global_acc_list)\n",
    "print('Non-IID | total comm rounds', len(global_acc_list))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noniid_df = pd.DataFrame(list(zip(global_acc_list, global_loss_list)), columns =['global_acc_list', 'global_loss_list'])\n",
    "noniid_df.to_csv('CIFAR-10_Non-IID.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
